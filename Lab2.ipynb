{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HmQat-50cQq",
        "outputId": "95d80178-fdb3-437c-e54c-8c26e7b080d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk gensim scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lEoqiOx0idl",
        "outputId": "bc191bfe-d592-4eef-fbba-ccc13cc70fcf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample dataset\n",
        "\n",
        "documents = [\n",
        "    \"The movie was fantastic with brilliant acting\",\n",
        "    \"I did not like the movie it was boring\",\n",
        "    \"The film had a great story and excellent visuals\",\n",
        "    \"Terrible movie with poor direction and weak plot\",\n",
        "    \"Amazing performance by the actors and a good script\",\n",
        "    \"The movie was average but the music was nice\"\n",
        "]\n",
        "\n",
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyX9NMtN0j9G",
        "outputId": "a44a4dc8-4ff0-4fd8-f4e5-45ce131d7478"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The movie was fantastic with brilliant acting', 'I did not like the movie it was boring', 'The film had a great story and excellent visuals', 'Terrible movie with poor direction and weak plot', 'Amazing performance by the actors and a good script', 'The movie was average but the music was nice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bag-of-Words (Count Occurrence)\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_counts = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\")\n",
        "print(count_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nBag-of-Words (Count Occurrence):\")\n",
        "print(bow_counts.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSKcYAJt05_-",
        "outputId": "3872d458-e990-49d5-a313-c6f9be066659"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "['acting' 'actors' 'amazing' 'and' 'average' 'boring' 'brilliant' 'but'\n",
            " 'by' 'did' 'direction' 'excellent' 'fantastic' 'film' 'good' 'great'\n",
            " 'had' 'it' 'like' 'movie' 'music' 'nice' 'not' 'performance' 'plot'\n",
            " 'poor' 'script' 'story' 'terrible' 'the' 'visuals' 'was' 'weak' 'with']\n",
            "\n",
            "Bag-of-Words (Count Occurrence):\n",
            "[[1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1]\n",
            " [0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 2 0 2 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-Words (Normalized Count Occurrence) (L2 Normalization)\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "count_vectorizer_norm = CountVectorizer()\n",
        "bow_counts = count_vectorizer_norm.fit_transform(documents)\n",
        "bow_normalized = normalize(bow_counts, norm='l2', axis=1)\n",
        "\n",
        "print(\"Vocabulary:\")\n",
        "print(count_vectorizer_norm.get_feature_names_out())\n",
        "\n",
        "print(\"\\nNormalized Bag-of-Words (L2 Normalization):\")\n",
        "print(bow_normalized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhTsoI9u08hz",
        "outputId": "36eeb22d-24e8-434e-c143-9eb88c102984"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "['acting' 'actors' 'amazing' 'and' 'average' 'boring' 'brilliant' 'but'\n",
            " 'by' 'did' 'direction' 'excellent' 'fantastic' 'film' 'good' 'great'\n",
            " 'had' 'it' 'like' 'movie' 'music' 'nice' 'not' 'performance' 'plot'\n",
            " 'poor' 'script' 'story' 'terrible' 'the' 'visuals' 'was' 'weak' 'with']\n",
            "\n",
            "Normalized Bag-of-Words (L2 Normalization):\n",
            "[[0.37796447 0.         0.         0.         0.         0.\n",
            "  0.37796447 0.         0.         0.         0.         0.\n",
            "  0.37796447 0.         0.         0.         0.         0.\n",
            "  0.         0.37796447 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.37796447\n",
            "  0.         0.37796447 0.         0.37796447]\n",
            " [0.         0.         0.         0.         0.         0.35355339\n",
            "  0.         0.         0.         0.35355339 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.35355339\n",
            "  0.35355339 0.35355339 0.         0.         0.35355339 0.\n",
            "  0.         0.         0.         0.         0.         0.35355339\n",
            "  0.         0.35355339 0.         0.        ]\n",
            " [0.         0.         0.         0.35355339 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.35355339\n",
            "  0.         0.35355339 0.         0.35355339 0.35355339 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.35355339 0.         0.35355339\n",
            "  0.35355339 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.35355339 0.         0.\n",
            "  0.         0.         0.         0.         0.35355339 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.35355339 0.         0.         0.         0.\n",
            "  0.35355339 0.35355339 0.         0.         0.35355339 0.\n",
            "  0.         0.         0.35355339 0.35355339]\n",
            " [0.         0.35355339 0.35355339 0.35355339 0.         0.\n",
            "  0.         0.         0.35355339 0.         0.         0.\n",
            "  0.         0.         0.35355339 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.35355339\n",
            "  0.         0.         0.35355339 0.         0.         0.35355339\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.2773501  0.\n",
            "  0.         0.2773501  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.2773501  0.2773501  0.2773501  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.5547002\n",
            "  0.         0.5547002  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Representation\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\")\n",
        "print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4U3h6Dt0_i-",
        "outputId": "ccce2491-257d-4af3-f591-4f35ff15da28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "['acting' 'actors' 'amazing' 'and' 'average' 'boring' 'brilliant' 'but'\n",
            " 'by' 'did' 'direction' 'excellent' 'fantastic' 'film' 'good' 'great'\n",
            " 'had' 'it' 'like' 'movie' 'music' 'nice' 'not' 'performance' 'plot'\n",
            " 'poor' 'script' 'story' 'terrible' 'the' 'visuals' 'was' 'weak' 'with']\n",
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.4580532  0.         0.         0.         0.         0.\n",
            "  0.4580532  0.         0.         0.         0.         0.\n",
            "  0.4580532  0.         0.         0.         0.         0.\n",
            "  0.         0.27174425 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.23467289\n",
            "  0.         0.31711592 0.         0.37561017]\n",
            " [0.         0.         0.         0.         0.         0.40509636\n",
            "  0.         0.         0.         0.40509636 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.40509636\n",
            "  0.40509636 0.24032712 0.         0.         0.40509636 0.\n",
            "  0.         0.         0.         0.         0.         0.20754169\n",
            "  0.         0.28045324 0.         0.        ]\n",
            " [0.         0.         0.         0.26663367 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38513489\n",
            "  0.         0.38513489 0.         0.38513489 0.38513489 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.38513489 0.         0.1973149\n",
            "  0.38513489 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.27147051 0.         0.\n",
            "  0.         0.         0.         0.         0.3921214  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.2326296  0.         0.         0.         0.\n",
            "  0.3921214  0.3921214  0.         0.         0.3921214  0.\n",
            "  0.         0.         0.3921214  0.32154515]\n",
            " [0.         0.38513489 0.38513489 0.26663367 0.         0.\n",
            "  0.         0.         0.38513489 0.         0.         0.\n",
            "  0.         0.         0.38513489 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.38513489\n",
            "  0.         0.         0.38513489 0.         0.         0.1973149\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.36963444 0.\n",
            "  0.         0.36963444 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.21928901 0.36963444 0.36963444 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.37874721\n",
            "  0.         0.51180503 0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize Sentences for Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuEsVk-f1Cm2",
        "outputId": "c8e1503a-f91d-4c8e-8dbf-e4d7f0216958"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'movie', 'was', 'fantastic', 'with', 'brilliant', 'acting'], ['i', 'did', 'not', 'like', 'the', 'movie', 'it', 'was', 'boring'], ['the', 'film', 'had', 'a', 'great', 'story', 'and', 'excellent', 'visuals'], ['terrible', 'movie', 'with', 'poor', 'direction', 'and', 'weak', 'plot'], ['amazing', 'performance', 'by', 'the', 'actors', 'and', 'a', 'good', 'script'], ['the', 'movie', 'was', 'average', 'but', 'the', 'music', 'was', 'nice']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec Model\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_docs,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "m--zeynm1DzJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embeddings (Vector Representation)\n",
        "print(\"Vector for word 'movie':\")\n",
        "print(w2v_model.wv['movie'])\n",
        "\n",
        "print(\"\\nVector size:\", w2v_model.wv.vector_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiqpr6W01GrT",
        "outputId": "b6098cee-5890-44ee-f6a1-0c78a2914b59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for word 'movie':\n",
            "[ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            "\n",
            "Vector size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Similar Words using Word2Vec\n",
        "similar_words = w2v_model.wv.most_similar('movie')\n",
        "print(\"Words similar to 'movie':\")\n",
        "print(similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M28CJ_IJ1aI-",
        "outputId": "7d1bacd1-2490-4146-a604-ee03d9cb4f49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'movie':\n",
            "[('but', 0.19912627339363098), ('good', 0.17276281118392944), ('like', 0.1711830496788025), ('a', 0.17020903527736664), ('direction', 0.1528114229440689), ('terrible', 0.14860160648822784), ('nice', 0.14595982432365417), ('i', 0.0805894061923027), ('acting', 0.06437695026397705), ('with', 0.06408977508544922)]\n"
          ]
        }
      ]
    }
  ]
}