{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJp1bEC7tdLS",
        "outputId": "661f194b-b533-45a8-e32f-3bd9398a95ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEWDgklOuErY",
        "outputId": "89fe18d3-8644-4279-e0ac-fd76177e4e61"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"We planned a trip to the Andaman and Nicobar Islands in the month of December. We spent weeks making the plan, finalizing the itinerary, and coordinating bookings; however, our trip was unfortunately cancelled due to a flight-cancellation fiasco by Indigo Airlines.\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgxDirCKumim",
        "outputId": "ed00035d-f465-4734-d40e-df34c3158618"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We planned a trip to the Andaman and Nicobar Islands in the month of December. We spent weeks making the plan, finalizing the itinerary, and coordinating bookings; however, our trip was unfortunately cancelled due to a flight-cancellation fiasco by Indigo Airlines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Whitespace tokenization\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "wt = WhitespaceTokenizer()\n",
        "tokens_whitespace = wt.tokenize(text)\n",
        "print(\"Whitespace Tokenization: \", tokens_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buOkDBvXvJ0E",
        "outputId": "049dc304-b1d9-4c34-c7a5-eb3c989a281c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokenization:  ['We', 'planned', 'a', 'trip', 'to', 'the', 'Andaman', 'and', 'Nicobar', 'Islands', 'in', 'the', 'month', 'of', 'December.', 'We', 'spent', 'weeks', 'making', 'the', 'plan,', 'finalizing', 'the', 'itinerary,', 'and', 'coordinating', 'bookings;', 'however,', 'our', 'trip', 'was', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight-cancellation', 'fiasco', 'by', 'Indigo', 'Airlines.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation based tokenization\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "pt = WordPunctTokenizer()\n",
        "tokens_punct = pt.tokenize(text)\n",
        "print(\"Punctuation Tokenization: \", tokens_punct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUEy0MUEviDf",
        "outputId": "0decb25b-18ba-475a-b152-b628afa6bdec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation Tokenization:  ['We', 'planned', 'a', 'trip', 'to', 'the', 'Andaman', 'and', 'Nicobar', 'Islands', 'in', 'the', 'month', 'of', 'December', '.', 'We', 'spent', 'weeks', 'making', 'the', 'plan', ',', 'finalizing', 'the', 'itinerary', ',', 'and', 'coordinating', 'bookings', ';', 'however', ',', 'our', 'trip', 'was', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight', '-', 'cancellation', 'fiasco', 'by', 'Indigo', 'Airlines', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treebank tokenization\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tbt = TreebankWordTokenizer()\n",
        "tokens_treebank = tbt.tokenize(text)\n",
        "print(\"Treebank Tokenization: \", tokens_treebank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4k9hl0EvzHg",
        "outputId": "21926212-9d8b-4bca-cc77-02e537c87b99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treebank Tokenization:  ['We', 'planned', 'a', 'trip', 'to', 'the', 'Andaman', 'and', 'Nicobar', 'Islands', 'in', 'the', 'month', 'of', 'December.', 'We', 'spent', 'weeks', 'making', 'the', 'plan', ',', 'finalizing', 'the', 'itinerary', ',', 'and', 'coordinating', 'bookings', ';', 'however', ',', 'our', 'trip', 'was', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight-cancellation', 'fiasco', 'by', 'Indigo', 'Airlines', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet Tokenization\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tt = TweetTokenizer()\n",
        "tokens_tweet = tt.tokenize(text)\n",
        "print(\"Tweet Tokenization:\", tokens_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukGl_ju4w3im",
        "outputId": "953d8338-55d3-41f9-c47e-04be1a1d0247"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Tokenization: ['We', 'planned', 'a', 'trip', 'to', 'the', 'Andaman', 'and', 'Nicobar', 'Islands', 'in', 'the', 'month', 'of', 'December', '.', 'We', 'spent', 'weeks', 'making', 'the', 'plan', ',', 'finalizing', 'the', 'itinerary', ',', 'and', 'coordinating', 'bookings', ';', 'however', ',', 'our', 'trip', 'was', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight-cancellation', 'fiasco', 'by', 'Indigo', 'Airlines', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Word Expression (MWE) Tokenization\n",
        "from nltk.tokenize import MWETokenizer\n",
        "\n",
        "mwe = MWETokenizer([('let', \"'s\"), ('openai',)])\n",
        "tokens_mwe = mwe.tokenize(text.lower().split())\n",
        "print(\"MWE Tokenization:\", tokens_mwe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHYfWh3VxQ8U",
        "outputId": "7351c6be-f638-4dfc-947c-fc0238de3efc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MWE Tokenization: ['we', 'planned', 'a', 'trip', 'to', 'the', 'andaman', 'and', 'nicobar', 'islands', 'in', 'the', 'month', 'of', 'december.', 'we', 'spent', 'weeks', 'making', 'the', 'plan,', 'finalizing', 'the', 'itinerary,', 'and', 'coordinating', 'bookings;', 'however,', 'our', 'trip', 'was', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight-cancellation', 'fiasco', 'by', 'indigo', 'airlines.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "porter_stems = [ps.stem(word) for word in tokens_treebank]\n",
        "print(\"Porter Stemmer Output:\", porter_stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufsf4jovxUXD",
        "outputId": "e1125856-1c0c-4721-be3a-9c09a3edb507"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer Output: ['we', 'plan', 'a', 'trip', 'to', 'the', 'andaman', 'and', 'nicobar', 'island', 'in', 'the', 'month', 'of', 'december.', 'we', 'spent', 'week', 'make', 'the', 'plan', ',', 'final', 'the', 'itinerari', ',', 'and', 'coordin', 'book', ';', 'howev', ',', 'our', 'trip', 'wa', 'unfortun', 'cancel', 'due', 'to', 'a', 'flight-cancel', 'fiasco', 'by', 'indigo', 'airlin', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Snowball Stemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "ss = SnowballStemmer(\"english\")\n",
        "snowball_stems = [ss.stem(word) for word in tokens_treebank]\n",
        "print(\"Snowball Stemmer Output:\", snowball_stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afmRq6zOxXGT",
        "outputId": "2da53c11-725f-4fdd-93ed-af307a49fa0a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snowball Stemmer Output: ['we', 'plan', 'a', 'trip', 'to', 'the', 'andaman', 'and', 'nicobar', 'island', 'in', 'the', 'month', 'of', 'december.', 'we', 'spent', 'week', 'make', 'the', 'plan', ',', 'final', 'the', 'itinerari', ',', 'and', 'coordin', 'book', ';', 'howev', ',', 'our', 'trip', 'was', 'unfortun', 'cancel', 'due', 'to', 'a', 'flight-cancel', 'fiasco', 'by', 'indigo', 'airlin', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization (WordNet Lemmatizer)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens_treebank]\n",
        "print(\"Lemmatization Output:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0YEGXzIxadU",
        "outputId": "2647932e-44b0-4bf8-c5f5-5e7d593f88ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization Output: ['We', 'planned', 'a', 'trip', 'to', 'the', 'Andaman', 'and', 'Nicobar', 'Islands', 'in', 'the', 'month', 'of', 'December.', 'We', 'spent', 'week', 'making', 'the', 'plan', ',', 'finalizing', 'the', 'itinerary', ',', 'and', 'coordinating', 'booking', ';', 'however', ',', 'our', 'trip', 'wa', 'unfortunately', 'cancelled', 'due', 'to', 'a', 'flight-cancellation', 'fiasco', 'by', 'Indigo', 'Airlines', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zuXmnu7exaK2"
      }
    }
  ]
}